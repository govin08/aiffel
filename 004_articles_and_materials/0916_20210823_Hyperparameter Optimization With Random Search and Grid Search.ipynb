{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization With Random Search and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Grid Search for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7828571428571429\n",
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Wall time: 19.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun-joong\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.58039683 0.58039683 0.57246032        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.69674603 0.69674603 0.69087302        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.77857143\n",
      " 0.78285714 0.78285714 0.75444444        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.75166667\n",
      " 0.7768254  0.7768254  0.77531746        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.75166667\n",
      " 0.75492063 0.75642857 0.75325397        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# grid search logistic regression model on the sonar dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search logistic regression model on the sonar dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60) (208,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "LogisticRegression()\n",
      "<class 'sklearn.model_selection._split.RepeatedStratifiedKFold'>\n",
      "RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(model)\n",
    "print(type(cv))\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
       " 'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
       " 'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun-joong\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.58039683 0.58039683 0.57246032        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.53380952\n",
      " 0.69674603 0.69674603 0.69087302        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.77698413\n",
      " 0.78285714 0.78285714 0.75444444        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.75166667\n",
      " 0.7768254  0.7768254  0.77531746        nan        nan        nan\n",
      " 0.73865079 0.73396825        nan        nan        nan 0.75166667\n",
      " 0.75492063 0.75642857 0.75325397        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
      "             estimator=LogisticRegression(), n_jobs=-1,\n",
      "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
      "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
      "             scoring='accuracy')\n"
     ]
    }
   ],
   "source": [
    "print(type(search))\n",
    "print(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
      "             estimator=LogisticRegression(), n_jobs=-1,\n",
      "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
      "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
      "             scoring='accuracy')\n"
     ]
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7828571428571429\n",
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Search for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7897619047619049\n",
      "Best Hyperparameters: {'C': 4.878363034905756, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Wall time: 48.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sun-joong\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.73865079        nan 0.73396825        nan 0.54984127 0.56769841\n",
      " 0.53380952 0.53380952        nan        nan        nan        nan\n",
      " 0.73865079        nan 0.76730159        nan        nan 0.73396825\n",
      " 0.53380952        nan 0.78007937 0.53380952 0.73396825 0.53380952\n",
      " 0.76269841        nan 0.73865079        nan 0.73865079 0.7815873\n",
      " 0.53380952        nan 0.73865079        nan 0.73865079 0.77666667\n",
      "        nan 0.73865079 0.53380952        nan 0.67634921 0.77698413\n",
      " 0.53380952 0.53539683        nan 0.53380952        nan        nan\n",
      "        nan        nan        nan 0.73865079        nan 0.73396825\n",
      "        nan 0.73396825        nan        nan        nan        nan\n",
      " 0.76119048        nan 0.78126984 0.57888889        nan 0.53698413\n",
      "        nan 0.76380952 0.73865079 0.53380952        nan        nan\n",
      "        nan        nan 0.73865079 0.76896825        nan 0.60293651\n",
      " 0.53380952 0.73865079        nan 0.78       0.53380952        nan\n",
      " 0.53380952        nan 0.73865079 0.53380952        nan        nan\n",
      " 0.53380952        nan        nan 0.74611111        nan        nan\n",
      "        nan        nan 0.53380952        nan        nan        nan\n",
      "        nan 0.53380952 0.70142857        nan 0.68246032        nan\n",
      " 0.53380952 0.58547619        nan        nan 0.70309524        nan\n",
      " 0.73396825 0.75150794 0.73396825        nan        nan 0.73865079\n",
      " 0.75166667 0.77634921 0.73396825        nan 0.53380952 0.53380952\n",
      "        nan        nan 0.53380952        nan 0.53380952 0.7768254\n",
      " 0.78492063 0.53380952 0.53380952 0.73396825        nan 0.75960317\n",
      " 0.77214286        nan 0.53380952        nan 0.74825397        nan\n",
      " 0.53380952 0.73865079 0.73396825 0.73865079 0.53380952        nan\n",
      " 0.73396825 0.53380952 0.53380952 0.73865079        nan        nan\n",
      "        nan        nan 0.7768254  0.53380952 0.78126984        nan\n",
      "        nan        nan        nan 0.67293651        nan        nan\n",
      " 0.73396825 0.75968254 0.68246032        nan        nan 0.77507937\n",
      " 0.53380952        nan        nan 0.53380952        nan 0.73396825\n",
      " 0.77650794        nan 0.53380952        nan 0.73865079 0.53380952\n",
      " 0.76111111        nan        nan        nan 0.73396825 0.53380952\n",
      " 0.76365079 0.71261905 0.73396825 0.53380952        nan        nan\n",
      " 0.73396825        nan        nan 0.53380952 0.73396825 0.53380952\n",
      "        nan        nan        nan 0.7747619  0.7752381  0.76269841\n",
      "        nan 0.7897619  0.73396825        nan        nan 0.73396825\n",
      " 0.53698413        nan        nan        nan 0.53380952        nan\n",
      " 0.73396825        nan        nan        nan 0.53380952 0.73865079\n",
      " 0.74611111        nan 0.53380952 0.53380952        nan        nan\n",
      " 0.55785714 0.53380952 0.73865079 0.73865079        nan        nan\n",
      "        nan 0.75285714 0.73865079        nan 0.75968254        nan\n",
      " 0.76365079 0.53380952        nan        nan        nan 0.73865079\n",
      " 0.64428571        nan        nan 0.53380952        nan 0.53380952\n",
      "        nan 0.73865079        nan 0.53380952 0.53380952 0.73174603\n",
      " 0.77055556        nan 0.53380952 0.53380952        nan 0.58039683\n",
      " 0.73396825        nan 0.53380952        nan        nan 0.73396825\n",
      "        nan        nan 0.6697619  0.6652381  0.6665873         nan\n",
      " 0.73396825        nan 0.73396825 0.77650794        nan 0.53380952\n",
      "        nan        nan 0.53380952 0.53380952        nan        nan\n",
      "        nan 0.73396825        nan 0.67460317 0.53380952        nan\n",
      "        nan 0.69833333        nan        nan        nan 0.53380952\n",
      " 0.73396825        nan 0.76587302 0.73396825        nan 0.53380952\n",
      "        nan 0.67611111        nan 0.77063492 0.73865079 0.75603175\n",
      "        nan        nan 0.76571429 0.73396825        nan 0.53380952\n",
      "        nan 0.70674603 0.53380952 0.73396825 0.78285714 0.61738095\n",
      "        nan 0.53380952        nan 0.73396825 0.73865079 0.73865079\n",
      " 0.73396825 0.77825397 0.73396825        nan        nan 0.53380952\n",
      " 0.76111111        nan        nan        nan 0.76738095        nan\n",
      " 0.71579365        nan        nan        nan 0.53380952 0.53380952\n",
      " 0.73865079 0.7747619         nan 0.53380952 0.53380952 0.78007937\n",
      "        nan        nan 0.53380952 0.54984127 0.73865079 0.53380952\n",
      "        nan 0.53380952 0.53380952 0.73396825        nan 0.61896825\n",
      " 0.73396825 0.53380952 0.68246032        nan 0.75761905        nan\n",
      "        nan        nan        nan        nan        nan 0.53380952\n",
      "        nan 0.53380952        nan        nan 0.77373016        nan\n",
      "        nan        nan        nan 0.75968254        nan 0.73865079\n",
      " 0.75253968 0.53380952 0.73865079        nan        nan 0.73865079\n",
      " 0.53380952 0.53380952 0.74031746 0.53380952        nan        nan\n",
      " 0.53380952 0.53380952 0.53380952        nan        nan        nan\n",
      "        nan 0.53380952 0.69190476        nan 0.53380952 0.53380952\n",
      "        nan        nan 0.76539683        nan 0.53380952        nan\n",
      "        nan 0.6715873         nan        nan        nan        nan\n",
      " 0.53380952        nan        nan        nan        nan        nan\n",
      "        nan 0.73865079 0.53380952 0.53380952        nan 0.7468254\n",
      " 0.53380952 0.73865079        nan 0.73865079 0.53380952        nan\n",
      "        nan 0.73865079 0.53380952        nan        nan 0.53380952\n",
      "        nan        nan 0.76111111        nan 0.73865079        nan\n",
      "        nan 0.73396825        nan        nan        nan 0.78\n",
      " 0.73865079 0.73396825        nan        nan        nan        nan\n",
      "        nan 0.63325397 0.53380952        nan 0.53380952        nan\n",
      " 0.73865079        nan        nan 0.73230159        nan        nan\n",
      "        nan        nan 0.76555556        nan 0.73865079 0.73396825\n",
      " 0.67              nan 0.53380952        nan 0.76738095        nan\n",
      " 0.73865079        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# random search logistic regression model on the sonar dataset\n",
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5, 100)\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Grid Search revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "space['C'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "space['C'] = [4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "space['C'] = [4.86,4.87,4.88,4.89,4.9,4.91,4.92,4.93,4.94]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
