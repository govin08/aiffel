{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 뉴스 요약봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**루브릭 1. Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.**  \n",
    "분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.\n",
    "\n",
    "-> \n",
    "\n",
    "**루브릭 2. 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.**  \n",
    "모델 학습이 진행되면서 train loss와 validation loss가 감소하는 경향을 그래프를 통해 확인했으며, 실제 요약문에 있는 핵심 단어들이 요약 문장 안에 포함되었다.\n",
    "\n",
    "-> \n",
    "\n",
    "**루브릭 3. Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.**  \n",
    "두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교하고 분석 결과를 표로 정리하여 제시하였다.\n",
    "\n",
    "-> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "import urllib.request\n",
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62972</th>\n",
       "      <td>Hindi daily to not report on Raj CM till ordin...</td>\n",
       "      <td>Hindi daily Rajasthan Patrika on Wednesday ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90712</th>\n",
       "      <td>Scientists create two-headed rat after perform...</td>\n",
       "      <td>Chinese scientists created a two-headed rat af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43661</th>\n",
       "      <td>Arrogance by Trump, Mitron kills democratic po...</td>\n",
       "      <td>Veteran BJP leader Shatrughan Sinha on Thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68066</th>\n",
       "      <td>Malaysia bans travel to North Korea over escal...</td>\n",
       "      <td>Malaysia on Thursday said all its citizens are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67634</th>\n",
       "      <td>PM Modi breaks bow, throws arrow like javelin ...</td>\n",
       "      <td>PM Narendra Modi threw an arrow like a javelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48854</th>\n",
       "      <td>Congress divided India 70 years ago for petty ...</td>\n",
       "      <td>Speaking at the Lok Sabha on Wednesday, Prime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13779</th>\n",
       "      <td>AMU suspends 3 for holding prayer meet for sla...</td>\n",
       "      <td>Aligarh Muslim University has suspended three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>Deepika, Alia to appear together on Koffee Wit...</td>\n",
       "      <td>Karan Johar took to Twitter to confirm that Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43165</th>\n",
       "      <td>US won't succeed if it tries to divide EU on t...</td>\n",
       "      <td>German economy minister Peter Altmaier has sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17417</th>\n",
       "      <td>Toyota to make Suzuki cars at Bengaluru plant:...</td>\n",
       "      <td>Toyota has reportedly agreed to produce Suzuki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "62972  Hindi daily to not report on Raj CM till ordin...   \n",
       "90712  Scientists create two-headed rat after perform...   \n",
       "43661  Arrogance by Trump, Mitron kills democratic po...   \n",
       "68066  Malaysia bans travel to North Korea over escal...   \n",
       "67634  PM Modi breaks bow, throws arrow like javelin ...   \n",
       "48854  Congress divided India 70 years ago for petty ...   \n",
       "13779  AMU suspends 3 for holding prayer meet for sla...   \n",
       "15528  Deepika, Alia to appear together on Koffee Wit...   \n",
       "43165  US won't succeed if it tries to divide EU on t...   \n",
       "17417  Toyota to make Suzuki cars at Bengaluru plant:...   \n",
       "\n",
       "                                                    text  \n",
       "62972  Hindi daily Rajasthan Patrika on Wednesday ann...  \n",
       "90712  Chinese scientists created a two-headed rat af...  \n",
       "43661  Veteran BJP leader Shatrughan Sinha on Thursda...  \n",
       "68066  Malaysia on Thursday said all its citizens are...  \n",
       "67634  PM Narendra Modi threw an arrow like a javelin...  \n",
       "48854  Speaking at the Lok Sabha on Wednesday, Prime ...  \n",
       "13779  Aligarh Muslim University has suspended three ...  \n",
       "15528  Karan Johar took to Twitter to confirm that Al...  \n",
       "43165  German economy minister Peter Altmaier has sai...  \n",
       "17417  Toyota has reportedly agreed to produce Suzuki...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\govin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (test)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'upGrad learner switches to career in ML & Al with 90% salary hike'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(1)\n",
    "data['headlines'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "\n",
      "saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers\n",
      "upgrad learner switches to career in ml al with salary hike\n"
     ]
    }
   ],
   "source": [
    "temp_text = data['text'][0]\n",
    "temp_headlines = data['headlines'][0]\n",
    "\n",
    "print(temp_text)\n",
    "print(temp_headlines)\n",
    "print()\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_headlines, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       " 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years',\n",
       " 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govin\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['upgrad learner switches to career in ml al with salary hike',\n",
       " 'delhi techie wins free food from swiggy for one year on cred',\n",
       " 'new zealand end rohit sharma led india match winning streak',\n",
       " 'aegon life iterm insurance plan helps customers save tax',\n",
       " 'have known hirani for yrs what if metoo claims are not true sonam']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_headlines = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))\n",
    "\n",
    "clean_headlines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :',(len(data)))#데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "headlines_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998576657177715\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.2755693371289142\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 27105\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "      <td>union minister dharmendra pradhan wednesday cl...</td>\n",
       "      <td>sostoken odisha cm patnaik controls mining maf...</td>\n",
       "      <td>odisha cm patnaik controls mining mafia union ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "      <td>indian space research organisation wednesday u...</td>\n",
       "      <td>sostoken isro unveils bengaluru centre for man...</td>\n",
       "      <td>isro unveils bengaluru centre for manned space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>killed injured in saudi arabia floods</td>\n",
       "      <td>least people killed others injured saudi arabi...</td>\n",
       "      <td>sostoken killed injured in saudi arabia floods</td>\n",
       "      <td>killed injured in saudi arabia floods eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "      <td>investigators searching lost plane carrying ar...</td>\n",
       "      <td>sostoken seat cushions from missing plane carr...</td>\n",
       "      <td>seat cushions from missing plane carrying foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "      <td>agustawestland chopper scam co accused rajiv s...</td>\n",
       "      <td>sostoken agustawestland scam accused rajiv sax...</td>\n",
       "      <td>agustawestland scam accused rajiv saxena extra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headlines  \\\n",
       "19  odisha cm patnaik controls mining mafia union ...   \n",
       "21  isro unveils bengaluru centre for manned space...   \n",
       "22              killed injured in saudi arabia floods   \n",
       "29  seat cushions from missing plane carrying foot...   \n",
       "36  agustawestland scam accused rajiv saxena extra...   \n",
       "\n",
       "                                                 text  \\\n",
       "19  union minister dharmendra pradhan wednesday cl...   \n",
       "21  indian space research organisation wednesday u...   \n",
       "22  least people killed others injured saudi arabi...   \n",
       "29  investigators searching lost plane carrying ar...   \n",
       "36  agustawestland chopper scam co accused rajiv s...   \n",
       "\n",
       "                                        decoder_input  \\\n",
       "19  sostoken odisha cm patnaik controls mining maf...   \n",
       "21  sostoken isro unveils bengaluru centre for man...   \n",
       "22     sostoken killed injured in saudi arabia floods   \n",
       "29  sostoken seat cushions from missing plane carr...   \n",
       "36  sostoken agustawestland scam accused rajiv sax...   \n",
       "\n",
       "                                       decoder_target  \n",
       "19  odisha cm patnaik controls mining mafia union ...  \n",
       "21  isro unveils bengaluru centre for manned space...  \n",
       "22     killed injured in saudi arabia floods eostoken  \n",
       "29  seat cushions from missing plane carrying foot...  \n",
       "36  agustawestland scam accused rajiv saxena extra...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17644  3632 20732 ...  6702  9990  4383]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 5421\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 21684\n",
      "훈련 레이블의 개수 : 21684\n",
      "테스트 데이터의 개수 : 5421\n",
      "테스트 레이블의 개수 : 5421\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 42481\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 30727\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11754\n",
      "단어 집합에서 희귀 단어의 비율: 72.33115981262212\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 8.253857634072096\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76, 2323, 20, 5586, 152, 9, 6776, 1525, 1403, 2109, 834, 12, 1658, 367, 556, 4260, 4261, 2249, 10, 1724, 708, 17, 2109], [5241, 5404, 13, 294, 5997, 1953, 646, 1404, 413, 246, 485, 20, 893, 296, 264, 511, 1170, 737, 5404, 938, 388, 628, 4375, 294, 245, 380, 860, 403, 3692, 4262, 4375, 294], [161, 107, 316, 112, 2823, 367, 22, 287, 7791, 2025, 1103, 23, 171, 2226, 898, 7791, 616, 966, 70, 4781, 367, 81, 35, 165, 985, 294, 4163, 7791, 709, 372]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 18977\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 14319\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 4658\n",
      "단어 집합에서 희귀 단어의 비율: 75.45449754966539\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 14.208081198231836\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 75, 12, 596, 8, 622], [1, 22, 367, 1710, 1110, 577], [1, 58, 326, 7, 1939, 34], [1, 1711, 1064, 5, 64], [1, 163, 295, 1940, 368, 49, 3]]\n",
      "target\n",
      "decoder  [[75, 12, 596, 8, 622, 2], [22, 367, 1710, 1110, 577, 2], [58, 326, 7, 1939, 34, 2], [1711, 1064, 5, 64, 2], [163, 295, 1940, 368, 49, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 11\n",
      "삭제할 테스트 데이터의 개수 : 2\n",
      "훈련 데이터의 개수 : 21673\n",
      "훈련 레이블의 개수 : 21673\n",
      "테스트 데이터의 개수 : 5419\n",
      "테스트 레이블의 개수 : 5419\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 128)      1024000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 50, 256),    394240      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50, 256),    525312      ['lstm[0][0]']                   \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 128)    256000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 50, 256),    525312      ['lstm_1[0][0]']                 \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 256),  394240      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 2000)   514000      ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 128)      1024000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 50, 256),    394240      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50, 256),    525312      ['lstm[0][0]']                   \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 128)    256000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 50, 256),    525312      ['lstm_1[0][0]']                 \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 256),  394240      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 256),  131328     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 50))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 512)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 2000)   1026000     ['concat_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 553s 6s/step - loss: 4.9200 - val_loss: 4.5330\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 619s 7s/step - loss: 4.5007 - val_loss: 4.3489\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 673s 8s/step - loss: 4.3303 - val_loss: 4.2383\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 752s 9s/step - loss: 4.1691 - val_loss: 4.0628\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 836s 10s/step - loss: 4.0056 - val_loss: 3.9390\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 1027s 12s/step - loss: 3.8553 - val_loss: 3.8198\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 1126s 13s/step - loss: 3.7152 - val_loss: 3.7211\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.5978 "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (head, text) in enumerate(zip(data['headlines'], data['text'])):\n",
    "    if idx == 20:\n",
    "        break\n",
    "    print(\"원문 :\", text)\n",
    "    print(\"실제 요약 :\", head)\n",
    "    print(\"예측 요약 :\", summarize(text, ratio=0.35))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization을 해봤는데 Abstractive Summarization, Extractive Summarization의 두가지가 성능 차이를 보였습니다.  \n",
    "\n",
    "- Abstractive Summarization  \n",
    "\n",
    "    Extractive Summarization보다 성능이 좋은 것 같고, 전처리를 더 잘하고, 모델 학습을 잘해서 성능을 개선 시키면 더 좋은 결과를 얻을 수 있을 것 같습니다.\n",
    "\n",
    "- Extractive Summarization  \n",
    "\n",
    "    문장을 넣었을 때 빈 리스트만 반환하는 경우도 있습니다. ratio를 조절해서 어느 정도 해결이 되지만, 예측된 요약이 적절하지는 않다고 생각됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
