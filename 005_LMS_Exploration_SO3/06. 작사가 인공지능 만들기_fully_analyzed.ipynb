{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4ff96f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde9a92",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127021c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8739d8e4",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fafb96",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b96d617",
   "metadata": {},
   "source": [
    "# 작사가 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377da8e",
   "metadata": {},
   "source": [
    "## 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc45cc",
   "metadata": {},
   "source": [
    "## 시퀀스? 스퀀스!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87293a9",
   "metadata": {},
   "source": [
    "## I 대신 am을 쓰면 반 이상은 맞더라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e125cb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 문장: <start> 나는 밥을 먹었다 \n",
      "Target 문장:  나는 밥을 먹었다 <end>\n"
     ]
    }
   ],
   "source": [
    "sentence = \" 나는 밥을 먹었다 \"\n",
    "# <start>는 문장의 시작 입니다. \n",
    "# <start> 토큰을 받은 순환 신경망은 \"나는\"을 출력한다.\n",
    "# 출력된 \"나는\"이라는 단어를 다시 입력으로 사용하고 이러한 반복을 통해 \"먹었다\"까지 \n",
    "# 글을 생성한다. 마지막으로 끝(완성)을 뜻하는 <end> 토큰을 생성하여 마무리 합니다. \n",
    "source_sentence = \"<start>\" + sentence\n",
    "target_sentence = sentence + \"<end>\"\n",
    "\n",
    "print(\"Source 문장:\", source_sentence)\n",
    "# Source 문장: <start> 나는 밥을 먹었다\n",
    "print(\"Target 문장:\", target_sentence)\n",
    "# Target 문장:  나는 밥을 먹었다 <end>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcf551",
   "metadata": {},
   "source": [
    "## 실습 (1) 데이터 다듬기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f94625",
   "metadata": {},
   "source": [
    "### `raw_corpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbae6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First Citizen:', 'Before we proceed any further, hear me speak.', '', 'All:', 'Speak, speak.', '', 'First Citizen:', 'You are all resolved rather to die than to famish?', '']\n"
     ]
    }
   ],
   "source": [
    "import os, re \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "file_path = '../../data/exploration_06/data/shakespeare.txt'\n",
    "with open(file_path, \"r\") as f:\n",
    "    raw_corpus = f.read().splitlines()\n",
    "\n",
    "print(raw_corpus[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d02ec3",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea85eef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before we proceed any further, hear me speak.\n",
      "Speak, speak.\n",
      "You are all resolved rather to die than to famish?\n"
     ]
    }
   ],
   "source": [
    "# enumerate() 함수를 이용하여 raw_corpus list 내에 저장된 문장과 그 문장의 인덱스를 반환 (인덱스, 문장 순)\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f311d",
   "metadata": {},
   "source": [
    "### `preprocess_sentence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1408e37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1581702",
   "metadata": {},
   "source": [
    "- before :__Linear-algebra is a central branch of mathetmatics. Is calculus more important than linear-algebra? I don't know.\"\n",
    "- after : \\<start\\>linear algebra is a central branch of mathetmatics. is calculus more important than linear algebra? i don t know. \\<end\\>\n",
    "- before : This @_is ;;;sample________sentence.\n",
    "- after : \\<start\\>this is sample sentence. \\<end\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894104d",
   "metadata": {},
   "source": [
    "### `corpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8588629c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> before we proceed any further , hear me speak . <end>',\n",
       " '<start> speak , speak . <end>',\n",
       " '<start> you are all resolved rather to die than to famish ? <end>',\n",
       " '<start> resolved . resolved . <end>',\n",
       " '<start> first , you know caius marcius is chief enemy to the people . <end>',\n",
       " '<start> we know t , we know t . <end>',\n",
       " '<start> let us kill him , and we ll have corn at our own price . <end>',\n",
       " '<start> is t a verdict ? <end>',\n",
       " '<start> no more talking on t let it be done away , away ! <end>',\n",
       " '<start> one word , good citizens . <end>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모을겁니다\n",
    "corpus = []\n",
    "\n",
    "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 앞서 구현한 preprocess_sentence() 함수를 이용하여 문장을 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b878c804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24015"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91100ac5",
   "metadata": {},
   "source": [
    "### `tensor`, `tokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2de099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  143   40 ...    0    0    0]\n",
      " [   2  110    4 ...    0    0    0]\n",
      " [   2   11   50 ...    0    0    0]\n",
      " ...\n",
      " [   2  149 4553 ...    0    0    0]\n",
      " [   2   34   71 ...    0    0    0]\n",
      " [   2  945   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f21048ccb80>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
    "# 더 잘 알기 위해 아래 문서들을 참고하면 좋습니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "def tokenize(corpus):\n",
    "    # 7000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
    "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
    "    # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=7000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    # tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    # tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e8a3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "24015\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus))\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd2a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=7000, filters=' ',\n",
    "                                                  oov_token=\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5895cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fcb1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84b42ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "24015\n"
     ]
    }
   ],
   "source": [
    "print(type(tensor))\n",
    "print(len(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9e32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c74b186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(24015, 21)\n"
     ]
    }
   ],
   "source": [
    "print(type(tensor))\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3c2b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(24015, 21)\n",
      "<start> before we proceed any further , hear me speak . <end>\n",
      "<start> speak , speak . <end>\n",
      "<start> you are all resolved rather to die than to famish ? <end>\n",
      "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
      "   0   0   0]\n",
      "[  2 110   4 110   5   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0]\n",
      "[   2   11   50   43 1201  316    9  201   74    9 3034   15    3    0\n",
      "    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(type(tensor))\n",
    "print(tensor.shape) #24015개의 문장, 각 문장은 21차원의 벡터\n",
    "print(corpus[0])\n",
    "print(corpus[1])\n",
    "print(corpus[2])\n",
    "print(tensor[0])\n",
    "print(tensor[1])\n",
    "print(tensor[2])"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7b82565c",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b538005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_keras_api_names', '_keras_api_names_v1', 'char_level', 'document_count', 'filters', 'fit_on_sequences', 'fit_on_texts', 'get_config', 'index_docs', 'index_word', 'lower', 'num_words', 'oov_token', 'sequences_to_matrix', 'sequences_to_texts', 'sequences_to_texts_generator', 'split', 'texts_to_matrix', 'texts_to_sequences', 'texts_to_sequences_generator', 'to_json', 'word_counts', 'word_docs', 'word_index']\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenizer))\n",
    "print(dir(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c059b49",
   "metadata": {},
   "source": [
    "- `fit_on_texts` : Updates internal vocabulary based on a list of texts.\n",
    "- `texts_to_sequences` : Transforms each text in texts to a sequence of integers.\n",
    "- `index_word` : \n",
    "- `num_words` : the maximum number of words to keep, based on word frequency\n",
    "- `filters` : a string where each element is a character that will be filtered from the texts.\n",
    "- `oov_token` : if given, it will be added to word_index and used to replace out-of-vocabulary words during text_to_sequence calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4867e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "11179\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenizer.index_word))\n",
    "print(len(tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d26777da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      " \n",
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.num_words)\n",
    "print(tokenizer.filters)\n",
    "print(tokenizer.oov_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd1598e",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fcf09da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  143   40  933  140  591    4  124   24  110]\n",
      " [   2  110    4  110    5    3    0    0    0    0]\n",
      " [   2   11   50   43 1201  316    9  201   74    9]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd12ca",
   "metadata": {},
   "source": [
    "### `tokenizer.index_word`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be0ebc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : .\n",
      "6 : the\n",
      "7 : and\n",
      "8 : i\n",
      "9 : to\n",
      "10 : of\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형대로 반환 (Ex. {index: '~~', index: '~~', ...})\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break\n",
    "print(0 in tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72b911",
   "metadata": {},
   "source": [
    "### `src_input`, `tgt_input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90ce19ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
      "   0   0]\n",
      "[143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be02a70",
   "metadata": {},
   "source": [
    "### `dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b6a9fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 20), (256, 20)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    " # tokenizer.num_words: 주어진 데이터의 문장들에서 빈도수가 높은 n개의 단어만 선택\n",
    " # tokenize() 함수에서 num_words를 7000개로 선언했기 때문에, tokenizer.num_words의 값은 7000\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
    "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
    "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2654c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24015\n",
      "256\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "print(len(src_input))\n",
    "print(256)\n",
    "print(len(src_input)//256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d4e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca8737f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24015, 2, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset_as_np_array = np.array([data for data in dataset])\n",
    "print(dataset_as_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7225b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
      "   0   0]\n",
      "[143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "[  2 110   4 110   5   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "[110   4 110   5   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_as_np_array[0,0])\n",
    "print(dataset_as_np_array[0,1])\n",
    "print(dataset_as_np_array[1,0])\n",
    "print(dataset_as_np_array[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f2de8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24015, 2, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset_as_np_array = np.array([data for data in dataset])\n",
    "print(dataset_as_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4418cd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2 3875    4   32   23   84    4   57    6 1508   10 4316    3    0\n",
      "    0    0    0    0    0    0]\n",
      "[3875    4   32   23   84    4   57    6 1508   10 4316    3    0    0\n",
      "    0    0    0    0    0    0]\n",
      "[  2  20   8  31 603  66  12 214  21 707   3   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "[ 20   8  31 603  66  12 214  21 707   3   0   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_as_np_array[0,0])\n",
    "print(dataset_as_np_array[0,1])\n",
    "print(dataset_as_np_array[1,0])\n",
    "print(dataset_as_np_array[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56df5ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(type(dataset))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "975b2f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 2, 256, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset_as_np_array = np.array([data for data in dataset])\n",
    "print(dataset_as_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e49336a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    7 3917 ...    0    0    0]\n",
      " [   2  765    8 ...    0    0    0]\n",
      " [   2   84   23 ...    0    0    0]\n",
      " ...\n",
      " [   2  377  681 ...    0    0    0]\n",
      " [   2  105 1853 ...    0    0    0]\n",
      " [   2  590    4 ...    0    0    0]]\n",
      "[[   7 3917  232 ...    0    0    0]\n",
      " [ 765    8  169 ...    0    0    0]\n",
      " [  84   23    9 ...    0    0    0]\n",
      " ...\n",
      " [ 377  681   12 ...    0    0    0]\n",
      " [ 105 1853   67 ...    0    0    0]\n",
      " [ 590    4   85 ...    0    0    0]]\n",
      "[[   2   62  147 ...    0    0    0]\n",
      " [   2   19    4 ...    0    0    0]\n",
      " [   2   49  969 ...    0    0    0]\n",
      " ...\n",
      " [   2    9  298 ...    0    0    0]\n",
      " [   2   86 1984 ...    0    0    0]\n",
      " [   2   22 2907 ...    0    0    0]]\n",
      "[[  62  147    8 ...    0    0    0]\n",
      " [  19    4   91 ...    0    0    0]\n",
      " [  49  969    4 ...    0    0    0]\n",
      " ...\n",
      " [   9  298   44 ...    0    0    0]\n",
      " [  86 1984    6 ...    0    0    0]\n",
      " [  22 2907   14 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_as_np_array[0,0])\n",
    "print(dataset_as_np_array[0,1])\n",
    "print(dataset_as_np_array[1,0])\n",
    "print(dataset_as_np_array[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6633af44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 20), (256, 20)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f858871",
   "metadata": {},
   "source": [
    "## 실습 (2) 인공지능 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23b35c",
   "metadata": {},
   "source": [
    "### `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb02d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
    "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
    "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "# embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만\n",
    "# 그만큼 충분한 데이터가 없으면 안좋은 결과 값을 가져옵니다!   \n",
    "embedding_size = 256 # 워드 벡터의 차원수를 말하며 단어가 추상적으로 표현되는 크기입니다.\n",
    "hidden_size = 1024 # 모델에 얼마나 많은 일꾼을 둘 것인가? 정도로 이해하면 좋다.\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963e31b",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1169f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 20, 7001), dtype=float32, numpy=\n",
       "array([[[ 2.78654683e-04,  2.76485607e-05, -5.15573920e-05, ...,\n",
       "          4.70115454e-04,  3.82514030e-04, -1.54235458e-04],\n",
       "        [ 8.14322557e-04, -9.85689330e-05, -7.31359105e-05, ...,\n",
       "          7.53924833e-04,  4.83653304e-04, -5.62071742e-04],\n",
       "        [ 1.28922565e-03, -3.59499973e-04, -1.21943798e-04, ...,\n",
       "          8.77031707e-04,  2.19627109e-04, -5.38604101e-04],\n",
       "        ...,\n",
       "        [ 8.81223066e-04, -2.45558377e-03, -2.35736510e-03, ...,\n",
       "          5.59365319e-04,  1.78067770e-03, -4.40267962e-04],\n",
       "        [ 9.33281612e-04, -3.05330008e-03, -2.76372139e-03, ...,\n",
       "          7.14695954e-04,  2.16254499e-03, -6.51257753e-04],\n",
       "        [ 9.33454547e-04, -3.56669631e-03, -3.10816802e-03, ...,\n",
       "          8.48840980e-04,  2.50983215e-03, -8.27763812e-04]],\n",
       "\n",
       "       [[ 2.78654683e-04,  2.76485607e-05, -5.15573920e-05, ...,\n",
       "          4.70115454e-04,  3.82514030e-04, -1.54235458e-04],\n",
       "        [ 7.06850842e-04,  1.28410975e-04, -1.16086856e-04, ...,\n",
       "          5.51305711e-04,  6.92539674e-04, -3.11935466e-04],\n",
       "        [ 5.93183329e-04,  5.23977760e-05, -1.77629190e-04, ...,\n",
       "          8.53967387e-04,  3.61286278e-04, -2.99591542e-04],\n",
       "        ...,\n",
       "        [ 7.37504684e-04, -3.64459888e-03, -4.04579379e-03, ...,\n",
       "          1.45776372e-03,  2.97982246e-03, -1.14280451e-03],\n",
       "        [ 6.10718795e-04, -3.94333946e-03, -4.17091371e-03, ...,\n",
       "          1.46380498e-03,  3.22912005e-03, -1.19808305e-03],\n",
       "        [ 4.75410809e-04, -4.17617150e-03, -4.26897639e-03, ...,\n",
       "          1.46169576e-03,  3.44996876e-03, -1.23338366e-03]],\n",
       "\n",
       "       [[ 2.78654683e-04,  2.76485607e-05, -5.15573920e-05, ...,\n",
       "          4.70115454e-04,  3.82514030e-04, -1.54235458e-04],\n",
       "        [ 5.08215802e-04,  8.44907117e-05, -1.99030590e-04, ...,\n",
       "          5.23298804e-04,  8.70611810e-04, -1.67425518e-04],\n",
       "        [ 7.57684291e-04,  1.84280856e-04, -5.22587681e-04, ...,\n",
       "          2.66106435e-05,  1.27538852e-03, -1.71513297e-04],\n",
       "        ...,\n",
       "        [ 6.03133376e-05, -2.90430943e-03, -2.90245214e-03, ...,\n",
       "          1.70583589e-04,  1.63201080e-03, -8.14022031e-04],\n",
       "        [ 9.76260781e-05, -3.38684791e-03, -3.25349765e-03, ...,\n",
       "          3.89944966e-04,  2.02237861e-03, -9.13369411e-04],\n",
       "        [ 9.65520157e-05, -3.79006728e-03, -3.54266702e-03, ...,\n",
       "          5.76527440e-04,  2.38782843e-03, -9.98920645e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.78654683e-04,  2.76485607e-05, -5.15573920e-05, ...,\n",
       "          4.70115454e-04,  3.82514030e-04, -1.54235458e-04],\n",
       "        [ 3.33606149e-04, -4.38880670e-06, -3.88969667e-04, ...,\n",
       "          8.13791354e-04,  5.08371508e-04, -2.24397227e-04],\n",
       "        [ 4.02890990e-04,  2.17446301e-04, -6.59146230e-04, ...,\n",
       "          1.12431636e-03,  6.42520376e-04, -7.42450720e-05],\n",
       "        ...,\n",
       "        [ 3.73148825e-04, -4.35183663e-03, -4.25191410e-03, ...,\n",
       "          1.28927419e-03,  3.42171080e-03, -1.01712940e-03],\n",
       "        [ 2.37021421e-04, -4.49742470e-03, -4.35840944e-03, ...,\n",
       "          1.29914563e-03,  3.58435255e-03, -1.06111343e-03],\n",
       "        [ 1.08008950e-04, -4.59808670e-03, -4.43864753e-03, ...,\n",
       "          1.30362611e-03,  3.72875598e-03, -1.08984299e-03]],\n",
       "\n",
       "       [[ 2.78654683e-04,  2.76485607e-05, -5.15573920e-05, ...,\n",
       "          4.70115454e-04,  3.82514030e-04, -1.54235458e-04],\n",
       "        [ 4.39216819e-04, -8.35595188e-07,  1.92511623e-04, ...,\n",
       "          7.14316731e-04,  5.25192881e-04, -1.66171390e-04],\n",
       "        [ 5.60986169e-04,  2.23985931e-04,  3.19511542e-04, ...,\n",
       "          7.02387188e-04,  6.19934057e-04, -4.84282427e-05],\n",
       "        ...,\n",
       "        [ 5.12810257e-05, -4.57052002e-03, -4.24602907e-03, ...,\n",
       "          1.21579506e-03,  3.74258822e-03, -9.79350996e-04],\n",
       "        [-6.00145686e-05, -4.63384483e-03, -4.31898655e-03, ...,\n",
       "          1.22988317e-03,  3.87960114e-03, -1.01508771e-03],\n",
       "        [-1.66244761e-04, -4.66980040e-03, -4.37734136e-03, ...,\n",
       "          1.23846089e-03,  3.99418129e-03, -1.03915448e-03]],\n",
       "\n",
       "       [[ 2.78654683e-04,  2.76485607e-05, -5.15573920e-05, ...,\n",
       "          4.70115454e-04,  3.82514030e-04, -1.54235458e-04],\n",
       "        [ 3.65218119e-04,  1.75157038e-04, -2.47050426e-04, ...,\n",
       "          7.63816060e-04,  6.84217375e-04, -4.26524377e-04],\n",
       "        [ 6.80364145e-04,  1.01386664e-04, -5.42501628e-04, ...,\n",
       "          7.59214337e-04,  6.58782839e-04, -6.65905944e-04],\n",
       "        ...,\n",
       "        [ 1.17165514e-03, -3.73462937e-03, -3.56157427e-03, ...,\n",
       "          1.12472859e-03,  2.64976849e-03, -5.66901290e-04],\n",
       "        [ 1.03540544e-03, -4.06019436e-03, -3.80681711e-03, ...,\n",
       "          1.18144439e-03,  2.91754748e-03, -6.87965250e-04],\n",
       "        [ 8.78174789e-04, -4.31260793e-03, -4.00552200e-03, ...,\n",
       "          1.22453633e-03,  3.15804104e-03, -7.84485077e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa32afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 2, 256, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset_as_np_array = np.array([data for data in dataset])\n",
    "print(dataset_as_np_array.shape) #batch, src/tgt, batch_size, length_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "642c26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 256, 20)\n"
     ]
    }
   ],
   "source": [
    "sample_as_np_array = np.array([data for data in dataset.take(1)])\n",
    "print(sample_as_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd906c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(256, 20, 7001)\n"
     ]
    }
   ],
   "source": [
    "prd_sample = model(src_sample)\n",
    "print(type(prd_sample))\n",
    "prd_sample_as_np_array = np.array([data for data in prd_sample])\n",
    "print(prd_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe63e59",
   "metadata": {},
   "source": [
    "- 이 모델의 입력값은 `src_sample`이다.\n",
    "  - `src_sample`의 shape은 (1, 1, 256, 20)으로 추정된다.\n",
    "- 이 모델의 입력값에 대한 라벨은 `tgt_sample`이다.\n",
    "  - `tgt_sample`의 shape은 (1, 1, 256, 20)으로 추정된다.\n",
    "  - `src_sample`과 `tgt_sample`은 `dataset.take(1)`와 같은 명령어로 한꺼번에 불러와진다.\n",
    "  - `dataset.take(1)`의 shape은 (1, 2, 256, 20)이다.\n",
    "  - `dataset`의 shape은 (93, 2, 256, 20)이었다.\n",
    "  이때 각각의 rank는 `steps_per_epoch`, src/tgt, 배치의 크기, 문장의 길이 (단어의 최대 개수)를 나타낸다.\n",
    "  - `dataset.take(1)`는 `dataset`의 첫번째 step까지를 포착한 것이다.\n",
    "- 이 모델의 출력값인 `model(src_sample)`을 `prd_sample`로 두었다.\n",
    "  - `prd_sample`의 shape은 (256, 20, 7001)로 추정된다.\n",
    "  - 앞의 256과 20의 의미에 대해서는 명확하다.\n",
    "  각각 배치 사이즈와 문장 길이이다.\n",
    "  - 7001은 예측할 단어를 one-hot vector로 표현했기 때문에 나타나는 것 같다.\n",
    "  - 즉, 이 tensor의 `[a,b,:]`는 7001차원의 one-hot vector가 나타날 것이다.\n",
    "  이 벡터는 a번째 배치의 b번째 문장이 주어졌을 때, 그 다음으로 나올 단어에 대한 one-hot vector일 것이다.\n",
    "  - 그러니까, `tgt_sample`과 `prd_sample`의 shape이 서로 다르다.\n",
    "  따라서 `prd_sample`에 대한 어떤 종류의 처리가 앞으로 필요할 것이다.\n",
    "- 위의 논리를 통해서 보면, dataset은 (그중에서도 src에 해당하는 부분은) 다음과 같은 hierachy가 존재함을 알 수 있다.\n",
    "\n",
    "dataset (93, 2, 256, 20)\n",
    "\n",
    "├── batch 1 (2, 256, 20)\n",
    "\n",
    "    ├── src (256, 20)\n",
    "\n",
    "        ├── sentence 1 (20,)\n",
    "\n",
    "        ：\n",
    "\n",
    "        └── sentence 20 (20,)\n",
    "\n",
    "    ：\n",
    "\n",
    "    └── tgt (256, 20)\n",
    "\n",
    "        ├── sentence 1 (20,)\n",
    "\n",
    "        ：\n",
    "\n",
    "        └── sentence 20 (20,)\n",
    "\n",
    "：\n",
    "\n",
    "├── batch 93 (2, 256, 20)\n",
    "\n",
    "    ├── src (256, 20)\n",
    "\n",
    "        ├── sentence 1 (20,)\n",
    "\n",
    "        ：\n",
    "\n",
    "        └── sentence 20 (20,)\n",
    "\n",
    "    ：\n",
    "\n",
    "    └── tgt (256, 20)\n",
    "\n",
    "        ├── sentence 1 (20,)\n",
    "\n",
    "        ：\n",
    "\n",
    "        └── sentence 20 (20,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56b7dc",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329c8c4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1792256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  7176025   \n",
      "=================================================================\n",
      "Total params: 22,607,961\n",
      "Trainable params: 22,607,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델의 구조를 확인합니다.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269263a",
   "metadata": {},
   "source": [
    "### `model.fit`, `model.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c779e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "93/93 [==============================] - 19s 180ms/step - loss: 3.4687\n",
      "Epoch 2/30\n",
      "93/93 [==============================] - 18s 188ms/step - loss: 2.8019\n",
      "Epoch 3/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 2.6990\n",
      "Epoch 4/30\n",
      "93/93 [==============================] - 19s 206ms/step - loss: 2.5956\n",
      "Epoch 5/30\n",
      "93/93 [==============================] - 19s 199ms/step - loss: 2.5294\n",
      "Epoch 6/30\n",
      "93/93 [==============================] - 18s 195ms/step - loss: 2.4764\n",
      "Epoch 7/30\n",
      "93/93 [==============================] - 18s 198ms/step - loss: 2.4202\n",
      "Epoch 8/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 2.3670\n",
      "Epoch 9/30\n",
      "93/93 [==============================] - 19s 201ms/step - loss: 2.3153\n",
      "Epoch 10/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 2.2641\n",
      "Epoch 11/30\n",
      "93/93 [==============================] - 19s 199ms/step - loss: 2.2150\n",
      "Epoch 12/30\n",
      "93/93 [==============================] - 19s 199ms/step - loss: 2.1685\n",
      "Epoch 13/30\n",
      "93/93 [==============================] - 19s 199ms/step - loss: 2.1217\n",
      "Epoch 14/30\n",
      "93/93 [==============================] - 19s 199ms/step - loss: 2.0747\n",
      "Epoch 15/30\n",
      "93/93 [==============================] - 19s 199ms/step - loss: 2.0284\n",
      "Epoch 16/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.9806\n",
      "Epoch 17/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.9327\n",
      "Epoch 18/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.8850\n",
      "Epoch 19/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.8362\n",
      "Epoch 20/30\n",
      "93/93 [==============================] - 19s 201ms/step - loss: 1.7867\n",
      "Epoch 21/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.7379\n",
      "Epoch 22/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.6898\n",
      "Epoch 23/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.6397\n",
      "Epoch 24/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.5916\n",
      "Epoch 25/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.5421\n",
      "Epoch 26/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.4923\n",
      "Epoch 27/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.4437\n",
      "Epoch 28/30\n",
      "93/93 [==============================] - 19s 200ms/step - loss: 1.3929\n",
      "Epoch 29/30\n",
      "93/93 [==============================] - 19s 201ms/step - loss: 1.3418\n",
      "Epoch 30/30\n",
      "93/93 [==============================] - 19s 201ms/step - loss: 1.2891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2100dce520>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer와 loss등은 차차 배웁니다\n",
    "# 혹시 미리 알고 싶다면 아래 문서를 참고하세요\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "# 양이 상당히 많은 편이니 지금 보는 것은 추천하지 않습니다\n",
    "\n",
    "# Adam 알고리즘을 구현하는 optimzier이며 어떤 optimzier를 써야할지 모른다면 Adam을 쓰는 것도 방법이다.\n",
    "# 우리가 학습을 할 때 최대한 틀리지 않는 방향으로 학습을 해야한다.\n",
    "# 여기서 얼마나 틀리는지(loss)를 알게하는 함수가 손실함수 이다.\n",
    "# 이 손실함수의 최소값을 찾는 것을 학습의 목표로 하며 여기서 최소값을 찾아가는 과정을 optimization 이라하고\n",
    "# 이를 수행하는 알고리즘을 optimizer(최적화)라고 한다.\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
    "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
    "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
    ")\n",
    "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
    "model.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
    "model.fit(dataset, epochs=30) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015228f8",
   "metadata": {},
   "source": [
    "## 실습 (3) 잘 만들어졌는지 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fe046",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59534717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장생성 함수 정의\n",
    "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20): #시작 문자열을 init_sentence 로 받으며 디폴트값은 <start> 를 받는다\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다 (도달 하지 못하였으면 while 루프를 돌면서 다음 단어를 예측)\n",
    "    while True: #루프를 돌면서 init_sentence에 단어를 하나씩 생성성\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4 \n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated #최종적으로 모델이 생성한 문장을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dff0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sentence = \"<start> he sat on\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12d31025",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tokenizer.texts_to_sequences([init_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbd1ba2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 27, 3180, 52]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eeebb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e04f365c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   2,   27, 3180,   52]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4df118ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_token = tokenizer.word_index[\"<end>\"]\n",
    "end_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "602fc91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 7001), dtype=float32, numpy=\n",
       "array([[[ -3.051416 ,   3.696951 ,  -8.831473 , ...,  -8.811118 ,\n",
       "          -8.012525 ,  -8.651165 ],\n",
       "        [ -3.2565126,   5.6126227,  -9.304058 , ..., -11.500596 ,\n",
       "         -14.960632 ,  -9.114545 ],\n",
       "        [ -4.4368005,   4.350048 , -11.46468  , ..., -12.195612 ,\n",
       "          -8.785845 , -11.178638 ],\n",
       "        [ -4.5176725,   3.8872557, -11.611043 , ...,  -8.24683  ,\n",
       "          -5.747051 , -11.250833 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model(test_tensor)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ff048b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-3.051416  ,  3.696951  , -8.831473  , -0.98473465, -4.0406938 ,\n",
       "       -5.806791  ,  4.6388636 ,  5.161111  ,  5.045443  ,  4.4601064 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0,0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afc1c701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 7001), dtype=float32, numpy=\n",
       "array([[[1.7487160e-05, 1.4910685e-02, 5.4009732e-08, ...,\n",
       "         5.5120374e-08, 1.2250024e-07, 6.4681338e-08],\n",
       "        [2.8071127e-06, 1.9956132e-02, 6.6350503e-09, ...,\n",
       "         7.3773343e-10, 2.3185969e-11, 8.0195193e-09],\n",
       "        [2.8612494e-06, 1.8734207e-02, 2.5373847e-09, ...,\n",
       "         1.2216492e-09, 3.6964902e-08, 3.3776331e-09],\n",
       "        [1.2564150e-06, 5.6149671e-03, 1.0435698e-09, ...,\n",
       "         3.0170398e-08, 3.6746937e-07, 1.4960939e-09]]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predict, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "048193ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([1.7487160e-05, 1.4910685e-02, 5.4009732e-08, 1.3812345e-04,\n",
       "       6.5025092e-06, 1.1119242e-06, 3.8244151e-02, 6.4472444e-02,\n",
       "       5.7430193e-02, 3.1983927e-02], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predict, axis = -1)[0,0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f72dd533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 7, 18,  4, 24]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(tf.nn.softmax(predict, axis = -1),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41e3d385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([24])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(tf.nn.softmax(predict, axis = -1),axis=-1)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "970501c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f67adc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([24])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "208ac27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   2,   27, 3180,   52]])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "762b713c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[24]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(predict_word,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0643f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[   2,   27, 3180,   52,   24]])>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bd5c657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 7001), dtype=float32, numpy=\n",
       "array([[[ -3.0514162,   3.696951 ,  -8.831473 , ...,  -8.811117 ,\n",
       "          -8.012525 ,  -8.651165 ],\n",
       "        [ -3.2565129,   5.6126227,  -9.304058 , ..., -11.500596 ,\n",
       "         -14.960633 ,  -9.114545 ],\n",
       "        [ -4.4368005,   4.350048 , -11.464679 , ..., -12.195612 ,\n",
       "          -8.785845 , -11.178638 ],\n",
       "        [ -4.517672 ,   3.8872557, -11.611043 , ...,  -8.24683  ,\n",
       "          -5.7470512, -11.250833 ],\n",
       "        [ -1.6840702,   2.3764992, -12.582758 , ..., -17.401278 ,\n",
       "         -17.443468 , -12.404248 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model(test_tensor)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c8d2b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-3.0514162,  3.696951 , -8.831473 , -0.9847348, -4.0406938,\n",
       "       -5.806791 ,  4.6388636,  5.161111 ,  5.045443 ,  4.4601064],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0,0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "918fb7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 7001), dtype=float32, numpy=\n",
       "array([[[1.7487144e-05, 1.4910685e-02, 5.4009732e-08, ...,\n",
       "         5.5120431e-08, 1.2250024e-07, 6.4681338e-08],\n",
       "        [2.8071124e-06, 1.9956131e-02, 6.6350498e-09, ...,\n",
       "         7.3773337e-10, 2.3185922e-11, 8.0195184e-09],\n",
       "        [2.8612467e-06, 1.8734209e-02, 2.5373872e-09, ...,\n",
       "         1.2216480e-09, 3.6964902e-08, 3.3776362e-09],\n",
       "        [1.2564160e-06, 5.6149671e-03, 1.0435707e-09, ...,\n",
       "         3.0170366e-08, 3.6746897e-07, 1.4960951e-09],\n",
       "        [3.4399192e-05, 1.9954059e-03, 6.3578232e-10, ...,\n",
       "         5.1363189e-12, 4.9241227e-12, 7.6003687e-10]]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predict, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59a95661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([1.7487144e-05, 1.4910685e-02, 5.4009732e-08, 1.3812345e-04,\n",
       "       6.5025092e-06, 1.1119242e-06, 3.8244151e-02, 6.4472444e-02,\n",
       "       5.7430193e-02, 3.1983927e-02], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predict, axis = -1)[0,0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb461976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[ 7, 18,  4, 24,  4]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(tf.nn.softmax(predict, axis = -1),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d885ea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(tf.nn.softmax(predict, axis = -1),axis=-1)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac47eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02104118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([4])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d818873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[   2,   27, 3180,   52,   24]])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7174a019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[4]])>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(predict_word,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a55fb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[   2,   27, 3180,   52,   24,    4]])>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2922cec9",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7885177b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he sat on me , and i am sure of all . <end> '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> he sat on\") # 시작문장으로 he를 넣어 문장생성 함수 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b7466",
   "metadata": {},
   "source": [
    "## 프로젝트 : 멋진 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbea017",
   "metadata": {},
   "source": [
    "## 프로젝트 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc1523",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280.438px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
